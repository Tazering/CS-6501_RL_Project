{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "import mani_skill.envs\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from mani_skill.utils import gym_utils\n",
    "from mani_skill.utils.wrappers.record import RecordEpisode\n",
    "from mani_skill.vector.wrappers.sb3 import ManiSkillSB3VectorEnv\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "SEED = 17\n",
    "NUM_ENVS = 8\n",
    "total_timesteps = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "states, _ = env.reset()\n",
    "check_env(env, warn = True)\n",
    "eval_env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running the dqn network\n",
    "\n",
    "# dqn_model = DQN(policy = \"MlpPolicy\", buffer_size = 10000, tau = 1.0, target_update_interval = 1000, env = env, learning_rate = 1e-3, \n",
    "# batch_size = 64, gamma = .99, exploration_fraction = .1, learning_starts = 1000, verbose = 1, exploration_final_eps = .01)\n",
    "# dqn_model.learn(total_timesteps = total_timesteps, progress_bar = True)\n",
    "# dqn_model.save(\"dqn_cartpole\")\n",
    "\n",
    "\n",
    "def run_dqn(policy = \"MlpPolicy\", env = None, learning_rate = 1e-3, gamma = .99, save_file_name = \"\"):\n",
    "    dqn_model = DQN(policy = policy, buffer_size = 10000, tau = 1.0, target_update_interval = 1000, env = env, learning_rate = learning_rate, \n",
    "    batch_size = 64, gamma = gamma, exploration_fraction = .1, learning_starts = 1000, verbose = 1, exploration_final_eps = .01)\n",
    "    dqn_model.learn(total_timesteps = total_timesteps, progress_bar = True)\n",
    "    dqn_model.save(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_reward(model_name, eval_env, iterations = 10):\n",
    "\n",
    "    model = DQN.load(model_name)\n",
    "    total_rewards_list = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        obs, _ = eval_env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        truncated = False\n",
    "\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic = True)\n",
    "            obs, reward, done, truncated, info = eval_env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            if truncated:\n",
    "                break\n",
    "\n",
    "        total_rewards_list.append(total_reward/500)\n",
    "        print(f\"Iteration: {_}\\nTotal Rewards {total_reward}\")\n",
    "    \n",
    "    return total_rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record a video\n",
    "# print(\"Recording a video...\")\n",
    "# video_frames = []\n",
    "# obs, _ = eval_env.reset()\n",
    "# done = False\n",
    "\n",
    "# while not done:\n",
    "#     frame = eval_env.render()\n",
    "#     video_frames.append(frame)\n",
    "#     action, _ = dqn_model.predict(obs, deterministic = True)\n",
    "#     obs, reward, done, truncated, info = eval_env.step(action)\n",
    "#     if truncated:\n",
    "#         break\n",
    "\n",
    "# eval_env.close()\n",
    "\n",
    "# # save the video\n",
    "# os.makedirs(\"videos\", exist_ok = True)\n",
    "# video_path = os.path.join(\"videos\", \"dqn_cartpole_video.mp4\")\n",
    "# imageio.mimsave(video_path, video_frames, fps = 30)\n",
    "# print(f\"Video saved to {video_path}\")\n",
    "\n",
    "def record_video(model = None, env = None, video_name = None):\n",
    "    print(\"Recording a video...\")\n",
    "    video_frames = []\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        frame = eval_env.render()\n",
    "        video_frames.append(frame)\n",
    "        action, _ = model.predict(obs, deterministic = True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        if truncated:\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # save the video\n",
    "    os.makedirs(\"videos\", exist_ok = True)\n",
    "    video_path = os.path.join(\"videos\", f\"{video_name}.mp4\")\n",
    "    imageio.mimsave(video_path, video_frames, fps = 30)\n",
    "    print(f\"Video saved to {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Run the Tests\n",
    "####################################\n",
    "\n",
    "iterations = [100000, 200000]\n",
    "learning_rate = [1e-1, 1e-3, 1e-5]\n",
    "gamma = [.99]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = get_total_reward(\"dqn_cartpole\", eval_env, iterations = 100)\n",
    "print(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"DQN Average Reward\")\n",
    "plt.plot(total_rewards, color = \"red\", label = \"alpha = .01\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Episode Steps\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# record a video\n",
    "print(\"Recording a video...\")\n",
    "video_frames = []\n",
    "obs, _ = eval_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    frame = eval_env.render()\n",
    "    video_frames.append(frame)\n",
    "    action, _ = dqn_model.predict(obs, deterministic = True)\n",
    "    obs, reward, done, truncated, info = eval_env.step(action)\n",
    "    if truncated:\n",
    "        break\n",
    "\n",
    "eval_env.close()\n",
    "\n",
    "# save the video\n",
    "os.makedirs(\"videos\", exist_ok = True)\n",
    "video_path = os.path.join(\"videos\", \"dqn_cartpole_video.mp4\")\n",
    "imageio.mimsave(video_path, video_frames, fps = 30)\n",
    "print(f\"Video saved to {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maniskill_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
